{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CARLA XR Documentation Welcome to the CARLA XR documentation. This project adds Extended Reality functionalities for educating autonomous driving on CARLA, an open-source autonomous driving simulator. It is based on CARLA 0.9.13. The platform of development is Windows PC with Oculus Quest2 headset. Although the primary headset in use for this project is Oculus Quest2, since the development is based on OpenXR rather than the proprietary plugin from Oculus, the result should be easy to transfer to other headsets as well. Getting Started This section contains guidance for setting up the software environment and run the simulation scenarios. Dependencies Installation \u2014 Install the CARLA fork of Unreal Engine 4.26 and other dependencies. Run XR Simulation \u2014 Procedures to run the simulation in XR. XR Implementations This section contains the technical details for implementing XR functionalities to CARLA. Information in this section might be helpful for future development. Preparation and Environment Setup \u2014 Preparation before development based on stock CARLA. VR Camera Attachment \u2014 Primary component to turn CARLA into VR. Vehicle Mesh Rendering and Collision \u2014 The separation of high-fidelity rendering and collision handling. Animation and User Interaction \u2014 The implementation of vehicle animation and feedback. Mixed Reality \u2014 The undesireable implementation of mixed reality. References CARLA Documentation Unreal Engine Oculus Prerequisites Unreal Engine OpenXR Prerequisites Car Configurator VaRest Spout TEST This is a test section TEST2 This is another test function","title":"Home"},{"location":"#carla-xr-documentation","text":"Welcome to the CARLA XR documentation. This project adds Extended Reality functionalities for educating autonomous driving on CARLA, an open-source autonomous driving simulator. It is based on CARLA 0.9.13. The platform of development is Windows PC with Oculus Quest2 headset. Although the primary headset in use for this project is Oculus Quest2, since the development is based on OpenXR rather than the proprietary plugin from Oculus, the result should be easy to transfer to other headsets as well.","title":"CARLA XR Documentation"},{"location":"#getting-started","text":"This section contains guidance for setting up the software environment and run the simulation scenarios. Dependencies Installation \u2014 Install the CARLA fork of Unreal Engine 4.26 and other dependencies. Run XR Simulation \u2014 Procedures to run the simulation in XR.","title":"Getting Started"},{"location":"#xr-implementations","text":"This section contains the technical details for implementing XR functionalities to CARLA. Information in this section might be helpful for future development. Preparation and Environment Setup \u2014 Preparation before development based on stock CARLA. VR Camera Attachment \u2014 Primary component to turn CARLA into VR. Vehicle Mesh Rendering and Collision \u2014 The separation of high-fidelity rendering and collision handling. Animation and User Interaction \u2014 The implementation of vehicle animation and feedback. Mixed Reality \u2014 The undesireable implementation of mixed reality.","title":"XR Implementations"},{"location":"#references","text":"CARLA Documentation Unreal Engine Oculus Prerequisites Unreal Engine OpenXR Prerequisites Car Configurator VaRest Spout","title":"References"},{"location":"#test","text":"This is a test section","title":"TEST"},{"location":"#test2","text":"This is another test function","title":"TEST2"},{"location":"anim_n_interact/","text":"Animation and User Interaction The animation of the steering wheel, speedometer, and tachometer was handled by ControlRig, which is an animation object inside Unreal Engine. It was set up with the skeleton that came with the Car Configurator project. To reduce the latency due to separation between input and output on client and server, a Flask server was developed on the client machine to transmit status data in real-time. When driving the vehicle, the steering wheel angle and vehicle velocity are sent to CARLA as JSON via REST API and VaRest, an Unreal Engine plugin for handling REST server communications. After receiving the JSON, the values are extracted, multiplied by a corresponding scaling factor, and applied to the ControlRig object, which results in the steering wheel, speedometer, and tachometer animation. Since the speedometer tick is not displayed linearly, the value shown on the speedometer can be inaccurate. To indicate the user with the most-accurate velocity, a velocity display was added at the center of the speedometer and tachometer panel. Because the UI components inside Unreal Engine do not support stereo rendering, users can only see the left eye of the headset displaying the velocity using UI components. To overcome this limitation, text mesh was used to display the velocity. It was also used at the central control panel of the vehicle to display the status of autonomous driving, which can also be set by JSON from REST API. The vehicle can produce dynamic engine sound as the velocity changes. The original sound wave was extracted from the Car Configurator project and edited using Audacity and FL Studio to get derived audio files for different states, such as accelerating and idle. Then, the audio of different states was mixed using SoundCue, an audio profile object inside Unreal Engine, as the velocity changed in real-time.","title":"Animation and User Interaction"},{"location":"anim_n_interact/#animation-and-user-interaction","text":"The animation of the steering wheel, speedometer, and tachometer was handled by ControlRig, which is an animation object inside Unreal Engine. It was set up with the skeleton that came with the Car Configurator project. To reduce the latency due to separation between input and output on client and server, a Flask server was developed on the client machine to transmit status data in real-time. When driving the vehicle, the steering wheel angle and vehicle velocity are sent to CARLA as JSON via REST API and VaRest, an Unreal Engine plugin for handling REST server communications. After receiving the JSON, the values are extracted, multiplied by a corresponding scaling factor, and applied to the ControlRig object, which results in the steering wheel, speedometer, and tachometer animation. Since the speedometer tick is not displayed linearly, the value shown on the speedometer can be inaccurate. To indicate the user with the most-accurate velocity, a velocity display was added at the center of the speedometer and tachometer panel. Because the UI components inside Unreal Engine do not support stereo rendering, users can only see the left eye of the headset displaying the velocity using UI components. To overcome this limitation, text mesh was used to display the velocity. It was also used at the central control panel of the vehicle to display the status of autonomous driving, which can also be set by JSON from REST API. The vehicle can produce dynamic engine sound as the velocity changes. The original sound wave was extracted from the Car Configurator project and edited using Audacity and FL Studio to get derived audio files for different states, such as accelerating and idle. Then, the audio of different states was mixed using SoundCue, an audio profile object inside Unreal Engine, as the velocity changed in real-time.","title":"Animation and User Interaction"},{"location":"dep_installation/","text":"Dependencies Installation This document provides guidance for installing the CARLA fork of Unreal Engine 4.26 and other software dependencies. A large portion of it was created based on the official CARLA website . Our tutorial adds the ability to run CARLA in the Virtual Reality environment using the Unreal Engine 4 (UE4) and the Oculus Quest headset. Please read carefully and follow all the steps, and the installation can take anywhere from 6 to 12 hours, depending on the hardware specification. Hardware Requirements x64 system. Linux configuration is possible, but this instruction only covers Windows. 200 GB disk space. Our customized CARLA package will take around 45 GB and the related major software installations (including UE4) will take 155 GB. An adequate GPU. NVIDIA GTX 1080 TI and above is required. In order to run the simulation at optimal quality, NVIDIA RTX 3080 and above is recommended. The GPU should have at least 8 GB of dedicated memory, although 16 GB is recommended. Two TCP ports. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. Software Requirements Make Install Make 3.8.1 by choosing \u201cComplete package, except sources\u201d from the download list. In the last step of installation, select \u201cDownload Sources\u201d. Check your Make version by running make --version in a terminal. If you get the error: 'make' is not recognized as an internal or external command, operable program or batch file , then Make is not successfully installed or added to path. CMake Install CMake using the Windows x64 Installer. Check your CMake version by running: cmake --version in a terminal, If you get the error 'cmake' is not recognized as an internal or external command, operable program or batch file , then CMake is not successfully installed or added to path. Git Install Git using the 64-bit Windows Installer. Accept all defaults. 7Zip Install 7-zip using the x64 Windows Installer. Accept all defaults. Python 1. Install Python 3.8.10 using the 64-bit Windows Installer. When prompted, add Python to system path. Check your Python version using python --version . 2. Upgrade pip and install the required dependencies. pip3 install --upgrade pip pip3 install --user setuptools pip3 install --user wheel Visual Studio 2019 Download Visual Studio 2019 and choose Community version. Using the installer to add the following packages (will take about 20GB): Windows 8.1 SDK (your windows version) Select it in the Installation details section on the right or go to the Indivdual Components tab and look under the SDKs, libraries, and frameworks heading. x64 Visual C++ Toolset. In the Workloads section, choose Desktop development with C++. This will enable a x64 command prompt that will be used for the build. Check that it has been installed correctly by pressing the Windows button and searching for x64. Be careful not to open a x86_x64 prompt. .NET framework 4.6.2. In the Workloads section, choose .NET desktop development and then in the Installation details panel on the right, select .NET Framework 4.6.2 development tools. This is required to build Unreal Engine. CARLA Unreal Engine 4.26 1. Download the modified version of the Unreal Enginer from here . 2. Navigate into the UE4 source folder, and run the configuration scripts: Setup.bat GenerateProjectFiles.bat 3. Build the Engine: Open the UE4.sln file inside the source folder with Visual Studio 2019. In the build bar ensure that you have selected 'Development Editor', 'Win64' and 'UnrealBuildTool' options. In the solution explorer, right-click UE4 and select Build . The build can take a few hours , depending on your hardware specification. Once the solution is compiled you can open the engine to check that everything was installed correctly by launching the executable Engine\\Binaries\\Win64\\UE4Editor.exe . If the installation was successful, this should be recognised by Unreal Engine's version selector. You can check this by right-clicking on any .uproject file and selecting Switch Unreal Engine version . You should see a pop-up showing Source Build at PATH where PATH is the installation path that you have chosen. If you can not see this selector or the Generate Visual Studio project files when you right-click on .uproject files, something went wrong with the Unreal Engine installation and you will likely need to reinstall it correctly. CARLA 0.9.13 Project 1. Download the project source code from here . Unzip the project into a standalone directory. 2. Navigate into the CARLA project directory and run command make launch in the x64 Native Tools Command Prompt for Visual Studio 2019 . 3. After a few minutes, you will see \"launching unreal editor\" and the UE4 window will pop up. During the loading process, the UE4 window will stop at 95% progress for approximately 1-2 hours . Be patient and let the process finish. After successfully entering the UE4, you will see \"Building Mesh Distance Fields\" and \"Compiling Shaders\", which can also take 1-2 hours to finish. OpenXR 1. Install Windows Oculus Application and accept all defaults. 2. Login with your Oculus account or sign up for one. 3. Configure and Install the OpenXR Runtime for Oculus follwing the instructions in here . Follow the instructions in the Oculus section. 4. Turn on the Oculus application, go to Settings > General . Under OpenXR Runtime , make sure \"Oculus is set as the active OpenXR Runtime\". G29 Wheel 1. Download the wheel support package from here and extract it into a folder called G29. 2. Download and install Logitech G Hub from here . 3. Plug the wheel into the computer, and make sure the wheel self calibrates to the center. 4. If something goes wrong, check for wheel conenction in the Logitech G Hub.","title":"Dependencies Installation"},{"location":"dep_installation/#dependencies-installation","text":"This document provides guidance for installing the CARLA fork of Unreal Engine 4.26 and other software dependencies. A large portion of it was created based on the official CARLA website . Our tutorial adds the ability to run CARLA in the Virtual Reality environment using the Unreal Engine 4 (UE4) and the Oculus Quest headset. Please read carefully and follow all the steps, and the installation can take anywhere from 6 to 12 hours, depending on the hardware specification.","title":"Dependencies Installation"},{"location":"dep_installation/#hardware-requirements","text":"x64 system. Linux configuration is possible, but this instruction only covers Windows. 200 GB disk space. Our customized CARLA package will take around 45 GB and the related major software installations (including UE4) will take 155 GB. An adequate GPU. NVIDIA GTX 1080 TI and above is required. In order to run the simulation at optimal quality, NVIDIA RTX 3080 and above is recommended. The GPU should have at least 8 GB of dedicated memory, although 16 GB is recommended. Two TCP ports. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications.","title":"Hardware Requirements"},{"location":"dep_installation/#software-requirements","text":"Make Install Make 3.8.1 by choosing \u201cComplete package, except sources\u201d from the download list. In the last step of installation, select \u201cDownload Sources\u201d. Check your Make version by running make --version in a terminal. If you get the error: 'make' is not recognized as an internal or external command, operable program or batch file , then Make is not successfully installed or added to path. CMake Install CMake using the Windows x64 Installer. Check your CMake version by running: cmake --version in a terminal, If you get the error 'cmake' is not recognized as an internal or external command, operable program or batch file , then CMake is not successfully installed or added to path. Git Install Git using the 64-bit Windows Installer. Accept all defaults. 7Zip Install 7-zip using the x64 Windows Installer. Accept all defaults.","title":"Software Requirements"},{"location":"dep_installation/#python","text":"1. Install Python 3.8.10 using the 64-bit Windows Installer. When prompted, add Python to system path. Check your Python version using python --version . 2. Upgrade pip and install the required dependencies. pip3 install --upgrade pip pip3 install --user setuptools pip3 install --user wheel","title":"Python"},{"location":"dep_installation/#visual-studio-2019","text":"Download Visual Studio 2019 and choose Community version. Using the installer to add the following packages (will take about 20GB): Windows 8.1 SDK (your windows version) Select it in the Installation details section on the right or go to the Indivdual Components tab and look under the SDKs, libraries, and frameworks heading. x64 Visual C++ Toolset. In the Workloads section, choose Desktop development with C++. This will enable a x64 command prompt that will be used for the build. Check that it has been installed correctly by pressing the Windows button and searching for x64. Be careful not to open a x86_x64 prompt. .NET framework 4.6.2. In the Workloads section, choose .NET desktop development and then in the Installation details panel on the right, select .NET Framework 4.6.2 development tools. This is required to build Unreal Engine.","title":"Visual Studio 2019"},{"location":"dep_installation/#carla-unreal-engine-426","text":"1. Download the modified version of the Unreal Enginer from here . 2. Navigate into the UE4 source folder, and run the configuration scripts: Setup.bat GenerateProjectFiles.bat 3. Build the Engine: Open the UE4.sln file inside the source folder with Visual Studio 2019. In the build bar ensure that you have selected 'Development Editor', 'Win64' and 'UnrealBuildTool' options. In the solution explorer, right-click UE4 and select Build . The build can take a few hours , depending on your hardware specification. Once the solution is compiled you can open the engine to check that everything was installed correctly by launching the executable Engine\\Binaries\\Win64\\UE4Editor.exe . If the installation was successful, this should be recognised by Unreal Engine's version selector. You can check this by right-clicking on any .uproject file and selecting Switch Unreal Engine version . You should see a pop-up showing Source Build at PATH where PATH is the installation path that you have chosen. If you can not see this selector or the Generate Visual Studio project files when you right-click on .uproject files, something went wrong with the Unreal Engine installation and you will likely need to reinstall it correctly.","title":"CARLA Unreal Engine 4.26"},{"location":"dep_installation/#carla-0913-project","text":"1. Download the project source code from here . Unzip the project into a standalone directory. 2. Navigate into the CARLA project directory and run command make launch in the x64 Native Tools Command Prompt for Visual Studio 2019 . 3. After a few minutes, you will see \"launching unreal editor\" and the UE4 window will pop up. During the loading process, the UE4 window will stop at 95% progress for approximately 1-2 hours . Be patient and let the process finish. After successfully entering the UE4, you will see \"Building Mesh Distance Fields\" and \"Compiling Shaders\", which can also take 1-2 hours to finish.","title":"CARLA 0.9.13 Project"},{"location":"dep_installation/#openxr","text":"1. Install Windows Oculus Application and accept all defaults. 2. Login with your Oculus account or sign up for one. 3. Configure and Install the OpenXR Runtime for Oculus follwing the instructions in here . Follow the instructions in the Oculus section. 4. Turn on the Oculus application, go to Settings > General . Under OpenXR Runtime , make sure \"Oculus is set as the active OpenXR Runtime\".","title":"OpenXR"},{"location":"dep_installation/#g29-wheel","text":"1. Download the wheel support package from here and extract it into a folder called G29. 2. Download and install Logitech G Hub from here . 3. Plug the wheel into the computer, and make sure the wheel self calibrates to the center. 4. If something goes wrong, check for wheel conenction in the Logitech G Hub.","title":"G29 Wheel"},{"location":"mr/","text":"Mixed Reality This project also attempted to implement Mixed Reality (MR) to CARLA using Oculus Quest 2. However, at this stage Oculus does not support passthrough API for UE 4.26. It has been achieved using a workaround, but the result is not satisfying. The MR was indirectly implemented using Unity since Oculus provides passthrough API to all Unity versions after 2019. To do so, an empty Unity project was created, and three meshes corresponding to the windshield and two side windows were modeled using Blender. The meshes were imported into the Unity project and applied rendered texture onto it. The rendered texture receives an image using a protocol called NDI. Because the official NDI support for Unreal Engine stopped at UE 4.23, another workaround must be implemented to transfer the video output from Unreal Engine to the Unity NDI receiver. On the Unreal Engine side, another protocol called Spout was implemented as the sender. Then, SpoutToNDI, software provided on the Spout official website was used to transform the Unreal Spout sender into an NDI sender. In this way, Unity can receive video output from Unreal. However, as the above illustration shows, the entire process is highly convoluted with two protocols. The video quality is severely degraded when Unity receives it. Although the two protocols are free to use, because of their opaque nature, it is also hard to optimize based on two protocols. Therefore, new approaches need to become up with and implemented.","title":"Mixed Reality"},{"location":"mr/#mixed-reality","text":"This project also attempted to implement Mixed Reality (MR) to CARLA using Oculus Quest 2. However, at this stage Oculus does not support passthrough API for UE 4.26. It has been achieved using a workaround, but the result is not satisfying. The MR was indirectly implemented using Unity since Oculus provides passthrough API to all Unity versions after 2019. To do so, an empty Unity project was created, and three meshes corresponding to the windshield and two side windows were modeled using Blender. The meshes were imported into the Unity project and applied rendered texture onto it. The rendered texture receives an image using a protocol called NDI. Because the official NDI support for Unreal Engine stopped at UE 4.23, another workaround must be implemented to transfer the video output from Unreal Engine to the Unity NDI receiver. On the Unreal Engine side, another protocol called Spout was implemented as the sender. Then, SpoutToNDI, software provided on the Spout official website was used to transform the Unreal Spout sender into an NDI sender. In this way, Unity can receive video output from Unreal. However, as the above illustration shows, the entire process is highly convoluted with two protocols. The video quality is severely degraded when Unity receives it. Although the two protocols are free to use, because of their opaque nature, it is also hard to optimize based on two protocols. Therefore, new approaches need to become up with and implemented.","title":"Mixed Reality"},{"location":"preparation_and_env_setup/","text":"Preparation and Environment Setup To prepare for the development, both CARLA and OpenXR need to be set up properly. For setting up CARLA, two major components, the source code of CARLA and a fork of Unreal Engine (UE) by the team of CARLA are required. Since CARLA uses a fork of UE 4.26 rather than the stock UE, the engine was cloned from the engine GitHub repository from CARLA and built using Visual Studio 2019, Windows 8.1 SDK, x64 Visual C++ Toolset, and .NET framework 4.6.2. The source project of CARLA was cloned from the simulator GitHub repository from CARLA. Due to the enormous size of the project, GitHub cannot host assets. They were downloaded separately using a batch script provided by the repository. Finally, the client PythonAPI and the server of CARLA were compiled using the x64 Native Tools Command Prompt. For setting up OpenXR, the OpenXR plugin should be enabled inside the CARLA project first. The Oculus app was downloaded and installed to enable Oculus Link, which can use the standalone VR headset as a desktop VR headset. Then, the Oculus app was allowed to install from Unknown Sources and enrolled in the Public Test Channel, and the OpenXR runtime for Oculus was installed. Finally, the Oculus OpenXR runtime was added to the Environment Variables. In this way, if the project is required to use another headset in the future, it can be easily set up by just replacing the path in the Environment Variables.","title":"Preparation and Environment Setup"},{"location":"preparation_and_env_setup/#preparation-and-environment-setup","text":"To prepare for the development, both CARLA and OpenXR need to be set up properly. For setting up CARLA, two major components, the source code of CARLA and a fork of Unreal Engine (UE) by the team of CARLA are required. Since CARLA uses a fork of UE 4.26 rather than the stock UE, the engine was cloned from the engine GitHub repository from CARLA and built using Visual Studio 2019, Windows 8.1 SDK, x64 Visual C++ Toolset, and .NET framework 4.6.2. The source project of CARLA was cloned from the simulator GitHub repository from CARLA. Due to the enormous size of the project, GitHub cannot host assets. They were downloaded separately using a batch script provided by the repository. Finally, the client PythonAPI and the server of CARLA were compiled using the x64 Native Tools Command Prompt. For setting up OpenXR, the OpenXR plugin should be enabled inside the CARLA project first. The Oculus app was downloaded and installed to enable Oculus Link, which can use the standalone VR headset as a desktop VR headset. Then, the Oculus app was allowed to install from Unknown Sources and enrolled in the Public Test Channel, and the OpenXR runtime for Oculus was installed. Finally, the Oculus OpenXR runtime was added to the Environment Variables. In this way, if the project is required to use another headset in the future, it can be easily set up by just replacing the path in the Environment Variables.","title":"Preparation and Environment Setup"},{"location":"run_simulation/","text":"Running the VR simulation Set up the Oculus Headset 1. Connect your headset to the computer using a USB-C wire and turn on the headset. 2. When prompted, Allow device to access data from the computer. 3. If Guardian is not found, create Guardian using the controller. 4. Turn on Oculus desktop program, go to device and make sure the headset is connected. 5. Enable Oculus Link, use this video as a reference. 6. Important : Oculus link must be enabled before turning on the Unreal Engine, or you will not be able to click the Run Simulation button. Set up the Unreal Engine 1. Navigate to your CARLA project source foler, and then \\Unreal\\CarlaUE4, double click CarlaUE4.uproject to launch the project. 2. Inside Unreal Editor, navigate to Content\\Carla\\Maps and double click to select the map (Map7 is used by default for the sample PythonAPI). 3. Inside the Unreal Editor, click >> on the top right corner to expand the toolbar, choose Active Play Mode > VR Preview . 4. Click Play to start simulation, you should be able to see the animation in your Oculus headset. Select VR Mode using spacebar 5. The first time you play the simulation, UE4 will show a white screen for a few minutes. Set up G29 Wheel Server (Optional) This step is optional. Only do it if you want the automatic wheel turning. You do NOT need to implement this step to read the wheel input as it is already included in the Pythong script. For further information on implementation, click here . 1. Open a new command window and navigate to directory G29/test . 2. Start the NodeJS express server by running node angle_phy.js . 3. You should be seeing a list of wheel information followed by wheel ready . If you encounter an error, your wheel might not be connected or your driver is not update to date. 4. Make sure the server is running before executing any related python scripts. Set up the Flask Server (Optional) This step is optional. However, not doing it would result in no animation inside the vehicle. 1. Open a new command window and navigate to directory G29/test . 2. Start the server by running python angle_sim.py . 3. You should be seeing a warning message followed by the server information. 4. Open page 127.0.0.1:5000/get_steer in a browser to verify that the server is running. Run the Scenario Demo 1. Navigate to Carla\\PythonAPI\\VR_Scripts 2. Run our selected python script using a terminal or an IDE. Some scripts will strictly require the wheel server and/or the Flask server to be running. 3. Important : Unreal Engine needs play the VR simulation before executing any Python script. 4. Important : Always terminate the Python script before exiting Unreal simulation. Driver's View Calibration (Optional) The view by default it aligned to the driver's seat. However, additional calibration might be needed to adjust the view. To do this, open a map and type init in the top right search box. Click on Level Initializer . Change the offsets X, Y, Z for an adjustment in the absolute position. Currently there is no way to change the orientation. Adjustments can only be made while the simulation is NOT running. Running the MR simulation Most steps for running the MR simulation is the same as VR. Instead of using Oculus Link, you should compile the Unity project under Unity\\CARLAUnityMR folder as Apk , and install it on Quest 2. Set up the Scenario Demo for MR 1. Click play on the Unreal scene 2. Open the compiled CARLAUnityMR App on Quest2 3. Open NDI to Spout.exe under SPOUTtoNDI\\bin 4. Select MR Mode using spacebar 5. Navigate to Carla\\PythonAPI\\VR_Scripts and run the script 6. Always terminate the Python script before exiting Unreal simulation. Note : this implementation runs MR at a low quality and is not recommended to use.","title":"Run XR Simulation"},{"location":"run_simulation/#running-the-vr-simulation","text":"","title":"Running the VR simulation"},{"location":"run_simulation/#set-up-the-oculus-headset","text":"1. Connect your headset to the computer using a USB-C wire and turn on the headset. 2. When prompted, Allow device to access data from the computer. 3. If Guardian is not found, create Guardian using the controller. 4. Turn on Oculus desktop program, go to device and make sure the headset is connected. 5. Enable Oculus Link, use this video as a reference. 6. Important : Oculus link must be enabled before turning on the Unreal Engine, or you will not be able to click the Run Simulation button.","title":"Set up the Oculus Headset"},{"location":"run_simulation/#set-up-the-unreal-engine","text":"1. Navigate to your CARLA project source foler, and then \\Unreal\\CarlaUE4, double click CarlaUE4.uproject to launch the project. 2. Inside Unreal Editor, navigate to Content\\Carla\\Maps and double click to select the map (Map7 is used by default for the sample PythonAPI). 3. Inside the Unreal Editor, click >> on the top right corner to expand the toolbar, choose Active Play Mode > VR Preview . 4. Click Play to start simulation, you should be able to see the animation in your Oculus headset. Select VR Mode using spacebar 5. The first time you play the simulation, UE4 will show a white screen for a few minutes.","title":"Set up the Unreal Engine"},{"location":"run_simulation/#set-up-g29-wheel-server-optional","text":"This step is optional. Only do it if you want the automatic wheel turning. You do NOT need to implement this step to read the wheel input as it is already included in the Pythong script. For further information on implementation, click here . 1. Open a new command window and navigate to directory G29/test . 2. Start the NodeJS express server by running node angle_phy.js . 3. You should be seeing a list of wheel information followed by wheel ready . If you encounter an error, your wheel might not be connected or your driver is not update to date. 4. Make sure the server is running before executing any related python scripts.","title":"Set up G29 Wheel Server (Optional)"},{"location":"run_simulation/#set-up-the-flask-server-optional","text":"This step is optional. However, not doing it would result in no animation inside the vehicle. 1. Open a new command window and navigate to directory G29/test . 2. Start the server by running python angle_sim.py . 3. You should be seeing a warning message followed by the server information. 4. Open page 127.0.0.1:5000/get_steer in a browser to verify that the server is running.","title":"Set up the Flask Server (Optional)"},{"location":"run_simulation/#run-the-scenario-demo","text":"1. Navigate to Carla\\PythonAPI\\VR_Scripts 2. Run our selected python script using a terminal or an IDE. Some scripts will strictly require the wheel server and/or the Flask server to be running. 3. Important : Unreal Engine needs play the VR simulation before executing any Python script. 4. Important : Always terminate the Python script before exiting Unreal simulation.","title":"Run the Scenario Demo"},{"location":"run_simulation/#drivers-view-calibration-optional","text":"The view by default it aligned to the driver's seat. However, additional calibration might be needed to adjust the view. To do this, open a map and type init in the top right search box. Click on Level Initializer . Change the offsets X, Y, Z for an adjustment in the absolute position. Currently there is no way to change the orientation. Adjustments can only be made while the simulation is NOT running.","title":"Driver's View Calibration (Optional)"},{"location":"run_simulation/#running-the-mr-simulation","text":"Most steps for running the MR simulation is the same as VR. Instead of using Oculus Link, you should compile the Unity project under Unity\\CARLAUnityMR folder as Apk , and install it on Quest 2.","title":"Running the MR simulation"},{"location":"run_simulation/#set-up-the-scenario-demo-for-mr","text":"1. Click play on the Unreal scene 2. Open the compiled CARLAUnityMR App on Quest2 3. Open NDI to Spout.exe under SPOUTtoNDI\\bin 4. Select MR Mode using spacebar 5. Navigate to Carla\\PythonAPI\\VR_Scripts and run the script 6. Always terminate the Python script before exiting Unreal simulation. Note : this implementation runs MR at a low quality and is not recommended to use.","title":"Set up the Scenario Demo for MR"},{"location":"vel_mesh_render_n_collision/","text":"Vehicle Mesh Rendering and Collision CARLA is designed primarily for autonomous driving research and used in third-person perspective, bird`s-eye view, or even without rendering. Therefore, the vehicle meshes and textures that come with CARLA have a low Level of Detail (LOD). To extend it as a VR application, a high LOD vehicle model should be imported and adjusted to be suitable in the CARLA environment. After searching and comparison on a variety of models from Unreal Marketplace and TurboSquid, an Audi A6 model from the Car Configurator project, which is licensed for free to use when working with Unreal Engine, developed by Epic Games and Audi was chosen. The model was extracted from the Car Configurator project after cleaning irrelevant Blueprint nodes inside the Car Configurator project. Unlike the Car Configurator project, it is unnecessary and unable for users of a VR autonomous driving simulator to see some components for functionalities, such as the engine and machine for the retractable top. Keeping them would consume much computational power as more polygons need to be rendered at every frame, which is amplified when using stereo rendering per frame in VR. Therefore, imperceptible components in VR were removed before importing the model to CARLA. CARLA stores vehicles as Blueprint classes. Each vehicle Blueprint contains a set of sensors for autonomous driving, and each four-wheeled vehicle was rigged with the same base skeleton. To avoid potential conflicts between mesh and skeleton when rigging and incompatibilities between mesh and sensor Blueprint, the vehicle mesh rendering and collision were handled separately. Because Audi A6, the model extracted from the Car Configurator, and Tesla Model 3, a vehicle Blueprint class already inside the CARLA project, has roughly the same dimension and hitbox both visually and physically, the Tesla Model 3 Blueprint was chosen to be responsible for handling collision. The initialization procedures were also programmed in the AutoAttachedCamera Blueprint. When a player-controlled Tesla Model 3 is spawned, besides repositioning the VR camera, the AutoAttachedCamera Blueprint also disables the mesh rendering of the low LOD Tesla Model 3, spawns the high LOD Audi A6, and disables its collider. This method can not only avoid the potential conflicts among mesh, skeleton, and Blueprint sensors but also can optimize the performance by showing the high-fidelity model and calculating the collisions using considerably fewer polygons.","title":"Vehicle Mesh Rendering and Collision"},{"location":"vel_mesh_render_n_collision/#vehicle-mesh-rendering-and-collision","text":"CARLA is designed primarily for autonomous driving research and used in third-person perspective, bird`s-eye view, or even without rendering. Therefore, the vehicle meshes and textures that come with CARLA have a low Level of Detail (LOD). To extend it as a VR application, a high LOD vehicle model should be imported and adjusted to be suitable in the CARLA environment. After searching and comparison on a variety of models from Unreal Marketplace and TurboSquid, an Audi A6 model from the Car Configurator project, which is licensed for free to use when working with Unreal Engine, developed by Epic Games and Audi was chosen. The model was extracted from the Car Configurator project after cleaning irrelevant Blueprint nodes inside the Car Configurator project. Unlike the Car Configurator project, it is unnecessary and unable for users of a VR autonomous driving simulator to see some components for functionalities, such as the engine and machine for the retractable top. Keeping them would consume much computational power as more polygons need to be rendered at every frame, which is amplified when using stereo rendering per frame in VR. Therefore, imperceptible components in VR were removed before importing the model to CARLA. CARLA stores vehicles as Blueprint classes. Each vehicle Blueprint contains a set of sensors for autonomous driving, and each four-wheeled vehicle was rigged with the same base skeleton. To avoid potential conflicts between mesh and skeleton when rigging and incompatibilities between mesh and sensor Blueprint, the vehicle mesh rendering and collision were handled separately. Because Audi A6, the model extracted from the Car Configurator, and Tesla Model 3, a vehicle Blueprint class already inside the CARLA project, has roughly the same dimension and hitbox both visually and physically, the Tesla Model 3 Blueprint was chosen to be responsible for handling collision. The initialization procedures were also programmed in the AutoAttachedCamera Blueprint. When a player-controlled Tesla Model 3 is spawned, besides repositioning the VR camera, the AutoAttachedCamera Blueprint also disables the mesh rendering of the low LOD Tesla Model 3, spawns the high LOD Audi A6, and disables its collider. This method can not only avoid the potential conflicts among mesh, skeleton, and Blueprint sensors but also can optimize the performance by showing the high-fidelity model and calculating the collisions using considerably fewer polygons.","title":"Vehicle Mesh Rendering and Collision"},{"location":"vr_cam_attachment/","text":"VR Camera Attachment The CARLA project was originally designed to use Unreal Engine purely for the environment and handle events and video output using Pygame. It is hard to implement VR directly on the client-side as Pygame barely has VR support. Therefore, VR was implemented on the server. To solve the discrepancy between client spawning event and server VR video output, a Blueprint class, which is a unique data structure when programming using Blueprint, the visualized programming interface inside Unreal Engine, named AutoAttachedCamera was developed, which is responsible for checking if the player vehicle exists and attach it to the spawned player vehicle automatically. it checks if a player-controlled vehicle exists and if it already attached itself to a vehicle at every frame. If a player-controller vehicle exists and it is not attached yet, it will transform itself into the driver seat of the vehicle. It also works after destroying the previous player vehicle and initializing a new one multiple times. In this way, the spawning event was properly handled between client and server.","title":"VR Camera Attachment"},{"location":"vr_cam_attachment/#vr-camera-attachment","text":"The CARLA project was originally designed to use Unreal Engine purely for the environment and handle events and video output using Pygame. It is hard to implement VR directly on the client-side as Pygame barely has VR support. Therefore, VR was implemented on the server. To solve the discrepancy between client spawning event and server VR video output, a Blueprint class, which is a unique data structure when programming using Blueprint, the visualized programming interface inside Unreal Engine, named AutoAttachedCamera was developed, which is responsible for checking if the player vehicle exists and attach it to the spawned player vehicle automatically. it checks if a player-controlled vehicle exists and if it already attached itself to a vehicle at every frame. If a player-controller vehicle exists and it is not attached yet, it will transform itself into the driver seat of the vehicle. It also works after destroying the previous player vehicle and initializing a new one multiple times. In this way, the spawning event was properly handled between client and server.","title":"VR Camera Attachment"}]}