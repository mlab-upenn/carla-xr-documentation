{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CARLA XR Documentation Welcome to the CARLA XR documentation. This project adds Extended Reality functionalities for educating autonomous driving on CARLA, an open-source autonomous driving simulator. It is based on CARLA 0.9.13. The platform of development is Windows PC with Oculus Quest2 headset. Although the primary headset in use for this project is Oculus Quest2, since the development is based on OpenXR rather than the proprietary plugin from Oculus, the result should be easy to transfer to other headsets as well. Getting Started This section contains guidance for setting up the software environment and run the simulation scenarios. Dependencies Installation \u2014 Install the CARLA fork of Unreal Engine 4.26 and other dependencies. Run XR Simulation \u2014 Procedures to run the simulation in XR. XR Implementations This section contains the technical details for implementing XR functionalities to CARLA. Information in this section might be helpful for future development. Preparation and Environment Setup \u2014 Preparation before development based on stock CARLA. VR Camera Attachment \u2014 Primary component to turn CARLA into VR. Vehicle Mesh Rendering and Collision \u2014 The separation of high-fidelity rendering and collision handling. Animation and User Interaction \u2014 The implementation of vehicle animation and feedback. Mixed Reality \u2014 The undesireable implementation of mixed reality. References CARLA Documentation Unreal Engine Oculus Prerequisites Unreal Engine OpenXR Prerequisites Car Configurator VaRest Spout","title":"Home"},{"location":"#carla-xr-documentation","text":"Welcome to the CARLA XR documentation. This project adds Extended Reality functionalities for educating autonomous driving on CARLA, an open-source autonomous driving simulator. It is based on CARLA 0.9.13. The platform of development is Windows PC with Oculus Quest2 headset. Although the primary headset in use for this project is Oculus Quest2, since the development is based on OpenXR rather than the proprietary plugin from Oculus, the result should be easy to transfer to other headsets as well.","title":"CARLA XR Documentation"},{"location":"#getting-started","text":"This section contains guidance for setting up the software environment and run the simulation scenarios. Dependencies Installation \u2014 Install the CARLA fork of Unreal Engine 4.26 and other dependencies. Run XR Simulation \u2014 Procedures to run the simulation in XR.","title":"Getting Started"},{"location":"#xr-implementations","text":"This section contains the technical details for implementing XR functionalities to CARLA. Information in this section might be helpful for future development. Preparation and Environment Setup \u2014 Preparation before development based on stock CARLA. VR Camera Attachment \u2014 Primary component to turn CARLA into VR. Vehicle Mesh Rendering and Collision \u2014 The separation of high-fidelity rendering and collision handling. Animation and User Interaction \u2014 The implementation of vehicle animation and feedback. Mixed Reality \u2014 The undesireable implementation of mixed reality.","title":"XR Implementations"},{"location":"#references","text":"CARLA Documentation Unreal Engine Oculus Prerequisites Unreal Engine OpenXR Prerequisites Car Configurator VaRest Spout","title":"References"},{"location":"anim_n_interact/","text":"Animation and User Interaction The animation of the steering wheel, speedometer, and tachometer was handled by ControlRig, which is an animation object inside Unreal Engine. It was set up with the skeleton that came with the Car Configurator project. To reduce the latency due to separation between input and output on client and server, a Flask server was developed on the client machine to transmit status data in real-time. When driving the vehicle, the steering wheel angle and vehicle velocity are sent to CARLA as JSON via REST API and VaRest, an Unreal Engine plugin for handling REST server communications. After receiving the JSON, the values are extracted, multiplied by a corresponding scaling factor, and applied to the ControlRig object, which results in the steering wheel, speedometer, and tachometer animation. Since the speedometer tick is not displayed linearly, the value shown on the speedometer can be inaccurate. To indicate the user with the most-accurate velocity, a velocity display was added at the center of the speedometer and tachometer panel. Because the UI components inside Unreal Engine do not support stereo rendering, users can only see the left eye of the headset displaying the velocity using UI components. To overcome this limitation, text mesh was used to display the velocity. It was also used at the central control panel of the vehicle to display the status of autonomous driving, which can also be set by JSON from REST API. The vehicle can produce dynamic engine sound as the velocity changes. The original sound wave was extracted from the Car Configurator project and edited using Audacity and FL Studio to get derived audio files for different states, such as accelerating and idle. Then, the audio of different states was mixed using SoundCue, an audio profile object inside Unreal Engine, as the velocity changed in real-time.","title":"Animation and User Interaction"},{"location":"anim_n_interact/#animation-and-user-interaction","text":"The animation of the steering wheel, speedometer, and tachometer was handled by ControlRig, which is an animation object inside Unreal Engine. It was set up with the skeleton that came with the Car Configurator project. To reduce the latency due to separation between input and output on client and server, a Flask server was developed on the client machine to transmit status data in real-time. When driving the vehicle, the steering wheel angle and vehicle velocity are sent to CARLA as JSON via REST API and VaRest, an Unreal Engine plugin for handling REST server communications. After receiving the JSON, the values are extracted, multiplied by a corresponding scaling factor, and applied to the ControlRig object, which results in the steering wheel, speedometer, and tachometer animation. Since the speedometer tick is not displayed linearly, the value shown on the speedometer can be inaccurate. To indicate the user with the most-accurate velocity, a velocity display was added at the center of the speedometer and tachometer panel. Because the UI components inside Unreal Engine do not support stereo rendering, users can only see the left eye of the headset displaying the velocity using UI components. To overcome this limitation, text mesh was used to display the velocity. It was also used at the central control panel of the vehicle to display the status of autonomous driving, which can also be set by JSON from REST API. The vehicle can produce dynamic engine sound as the velocity changes. The original sound wave was extracted from the Car Configurator project and edited using Audacity and FL Studio to get derived audio files for different states, such as accelerating and idle. Then, the audio of different states was mixed using SoundCue, an audio profile object inside Unreal Engine, as the velocity changed in real-time.","title":"Animation and User Interaction"},{"location":"dep_installation/","text":"Dependencies Installation This document provides guidance for installing the CARLA fork of Unreal Engine 4.26 and other software dependencies. Hardware Requirements x64 system 180 GB disk space An adequate GPU Two TCP ports and good internet connection Oculus Quest 2 Logitech G29 Wheel Software Requirements Visual Studio 2019 Windows 8.1 SDK. x64 Visual C++ Toolset .NET framework 4.6.2 Git 7Zip Python3 x64 Oculus Desktop App OpenXR for Oculus Install CARLA fork of Unreal Engine 4.26 To build the modified version of Unreal Engine: 1. Download the source code from this release . 2. Run the configuration scripts: Setup.bat GenerateProjectFiles.bat 3. Compile the modified engine: Open the UE4.sln file inside the source folder with Visual Studio 2019. In the build bar ensure that you have selected 'Development Editor', 'Win64' and 'UnrealBuildTool' options. Check this guide if you need any help. In the solution explorer, right-click UE4 and select Build . 4. Once the solution is compiled you can open the engine to check that everything was installed correctly by launching the executable Engine\\Binaries\\Win64\\UE4Editor.exe . If the installation was successful, this should be recognised by Unreal Engine's version selector. You can check this by right-clicking on any .uproject file and selecting Switch Unreal Engine version . You should see a pop-up showing Source Build at PATH where PATH is the installation path that you have chosen. If you can not see this selector or the Generate Visual Studio project files when you right-click on .uproject files, something went wrong with the Unreal Engine installation and you will likely need to reinstall it correctly. Set up Oculus Quest 2 1. Follow this document to enable Oculus Link. 2. Follow this blog to set up OpenXR for Oculus.","title":"Dependencies Installation"},{"location":"dep_installation/#dependencies-installation","text":"This document provides guidance for installing the CARLA fork of Unreal Engine 4.26 and other software dependencies.","title":"Dependencies Installation"},{"location":"dep_installation/#hardware-requirements","text":"x64 system 180 GB disk space An adequate GPU Two TCP ports and good internet connection Oculus Quest 2 Logitech G29 Wheel","title":"Hardware Requirements"},{"location":"dep_installation/#software-requirements","text":"Visual Studio 2019 Windows 8.1 SDK. x64 Visual C++ Toolset .NET framework 4.6.2 Git 7Zip Python3 x64 Oculus Desktop App OpenXR for Oculus","title":"Software Requirements"},{"location":"dep_installation/#install-carla-fork-of-unreal-engine-426","text":"To build the modified version of Unreal Engine: 1. Download the source code from this release . 2. Run the configuration scripts: Setup.bat GenerateProjectFiles.bat 3. Compile the modified engine: Open the UE4.sln file inside the source folder with Visual Studio 2019. In the build bar ensure that you have selected 'Development Editor', 'Win64' and 'UnrealBuildTool' options. Check this guide if you need any help. In the solution explorer, right-click UE4 and select Build . 4. Once the solution is compiled you can open the engine to check that everything was installed correctly by launching the executable Engine\\Binaries\\Win64\\UE4Editor.exe . If the installation was successful, this should be recognised by Unreal Engine's version selector. You can check this by right-clicking on any .uproject file and selecting Switch Unreal Engine version . You should see a pop-up showing Source Build at PATH where PATH is the installation path that you have chosen. If you can not see this selector or the Generate Visual Studio project files when you right-click on .uproject files, something went wrong with the Unreal Engine installation and you will likely need to reinstall it correctly.","title":"Install CARLA fork of Unreal Engine 4.26"},{"location":"dep_installation/#set-up-oculus-quest-2","text":"1. Follow this document to enable Oculus Link. 2. Follow this blog to set up OpenXR for Oculus.","title":"Set up Oculus Quest 2"},{"location":"mr/","text":"Mixed Reality This project also attempted to implement Mixed Reality (MR) to CARLA using Oculus Quest 2. However, at this stage Oculus does not support passthrough API for UE 4.26. It has been achieved using a workaround, but the result is not satisfying. The MR was indirectly implemented using Unity since Oculus provides passthrough API to all Unity versions after 2019. To do so, an empty Unity project was created, and three meshes corresponding to the windshield and two side windows were modeled using Blender. The meshes were imported into the Unity project and applied rendered texture onto it. The rendered texture receives an image using a protocol called NDI. Because the official NDI support for Unreal Engine stopped at UE 4.23, another workaround must be implemented to transfer the video output from Unreal Engine to the Unity NDI receiver. On the Unreal Engine side, another protocol called Spout was implemented as the sender. Then, SpoutToNDI, software provided on the Spout official website was used to transform the Unreal Spout sender into an NDI sender. In this way, Unity can receive video output from Unreal. However, as the above illustration shows, the entire process is highly convoluted with two protocols. The video quality is severely degraded when Unity receives it. Although the two protocols are free to use, because of their opaque nature, it is also hard to optimize based on two protocols. Therefore, new approaches need to become up with and implemented.","title":"Mixed Reality"},{"location":"mr/#mixed-reality","text":"This project also attempted to implement Mixed Reality (MR) to CARLA using Oculus Quest 2. However, at this stage Oculus does not support passthrough API for UE 4.26. It has been achieved using a workaround, but the result is not satisfying. The MR was indirectly implemented using Unity since Oculus provides passthrough API to all Unity versions after 2019. To do so, an empty Unity project was created, and three meshes corresponding to the windshield and two side windows were modeled using Blender. The meshes were imported into the Unity project and applied rendered texture onto it. The rendered texture receives an image using a protocol called NDI. Because the official NDI support for Unreal Engine stopped at UE 4.23, another workaround must be implemented to transfer the video output from Unreal Engine to the Unity NDI receiver. On the Unreal Engine side, another protocol called Spout was implemented as the sender. Then, SpoutToNDI, software provided on the Spout official website was used to transform the Unreal Spout sender into an NDI sender. In this way, Unity can receive video output from Unreal. However, as the above illustration shows, the entire process is highly convoluted with two protocols. The video quality is severely degraded when Unity receives it. Although the two protocols are free to use, because of their opaque nature, it is also hard to optimize based on two protocols. Therefore, new approaches need to become up with and implemented.","title":"Mixed Reality"},{"location":"preparation_and_env_setup/","text":"Preparation and Environment Setup To prepare for the development, both CARLA and OpenXR need to be set up properly. For setting up CARLA, two major components, the source code of CARLA and a fork of Unreal Engine (UE) by the team of CARLA are required. Since CARLA uses a fork of UE 4.26 rather than the stock UE, the engine was cloned from the engine GitHub repository from CARLA and built using Visual Studio 2019, Windows 8.1 SDK, x64 Visual C++ Toolset, and .NET framework 4.6.2. The source project of CARLA was cloned from the simulator GitHub repository from CARLA. Due to the enormous size of the project, GitHub cannot host assets. They were downloaded separately using a batch script provided by the repository. Finally, the client PythonAPI and the server of CARLA were compiled using the x64 Native Tools Command Prompt. For setting up OpenXR, the OpenXR plugin should be enabled inside the CARLA project first. The Oculus app was downloaded and installed to enable Oculus Link, which can use the standalone VR headset as a desktop VR headset. Then, the Oculus app was allowed to install from Unknown Sources and enrolled in the Public Test Channel, and the OpenXR runtime for Oculus was installed. Finally, the Oculus OpenXR runtime was added to the Environment Variables. In this way, if the project is required to use another headset in the future, it can be easily set up by just replacing the path in the Environment Variables.","title":"Preparation and Environment Setup"},{"location":"preparation_and_env_setup/#preparation-and-environment-setup","text":"To prepare for the development, both CARLA and OpenXR need to be set up properly. For setting up CARLA, two major components, the source code of CARLA and a fork of Unreal Engine (UE) by the team of CARLA are required. Since CARLA uses a fork of UE 4.26 rather than the stock UE, the engine was cloned from the engine GitHub repository from CARLA and built using Visual Studio 2019, Windows 8.1 SDK, x64 Visual C++ Toolset, and .NET framework 4.6.2. The source project of CARLA was cloned from the simulator GitHub repository from CARLA. Due to the enormous size of the project, GitHub cannot host assets. They were downloaded separately using a batch script provided by the repository. Finally, the client PythonAPI and the server of CARLA were compiled using the x64 Native Tools Command Prompt. For setting up OpenXR, the OpenXR plugin should be enabled inside the CARLA project first. The Oculus app was downloaded and installed to enable Oculus Link, which can use the standalone VR headset as a desktop VR headset. Then, the Oculus app was allowed to install from Unknown Sources and enrolled in the Public Test Channel, and the OpenXR runtime for Oculus was installed. Finally, the Oculus OpenXR runtime was added to the Environment Variables. In this way, if the project is required to use another headset in the future, it can be easily set up by just replacing the path in the Environment Variables.","title":"Preparation and Environment Setup"},{"location":"run_simulation/","text":"Run Simulation This document provides guidance for downloading, setting up, and running the simulation. Download the Project The project can be downloaded from this Google Drive folder . Due to the enormous size of the project, it cannot be hosted on Github. You can use 7Zip to unzip the project. Run the VR simulation Set up the Oculus Headset (before setting up Unreal Engine) 1. Turn on Oculus desktop program. 2. Turn on the headset. 3. Allow device to access data from the computer using the controller. 4. If Guardian is not found, create guardian using the controller. 5. Enable Oculus Link. Set up the Unreal Engine 1. Navigate to Carla_XR\\Unreal\\CarlaUE4, double click CarlaUE4.uproject to launch the Unreal project. 2. The Oculus link must be enabled before starting the Unreal Engine. 3. The Oculus app must show active connection before starting the Unreal Engine. 4. Navigate to \u201cContent\u201d \u2013 \u201cCarla\u201d \u2013 \u201cMaps\u201d and select the map(in bottom left of Unreal Engine) after launching the project. 5. There are 3 scenarios being adjusted for this project, which are Rural(Town07), City(Town10HD), and Highway(Town05). Set up the Flask Server 1. Open a new command window and navigate to directory G29/test . 2. Run the server: python angle_sim.py 3. The server must be running before executing any simulation. Set up the G29 Wheel 1. Open a new command window and navigate to directory G29/test . 2. Run the server : nodepython angle_phy.jspy 3. The wheel script must be running before executing any simulation Set up the Scenario Demo for VR 1. Navigate to Carla\\PythonAPI\\scenes 2. Click play on the Unreal scene 3. Select VR Mode using spacebar 4. Run the script 5. Always close the Python script before exiting Unreal scene Run the MR simulation Most procedures for running the MR simulation is the same as VR. Instead of using Oculus Link, you should compile the Unity project under Unity\\CARLAUnityMR folder as Apk , and install it on Quest2. Set up the Scenario Demo for MR 1. Navigate to Carla\\PythonAPI\\scenes 2. Click play on the Unreal scene 3. Open the compiled CARLAUnityMR App on Quest2 4. Open NDI to Spout.exe under SPOUTtoNDI\\bin 3. Select MR Mode using spacebar 4. Run the script 5. Always close the Python script before exiting Unreal scene Although MR is implemented, the result is undesireable. Calibration In Unreal project, type init in the top right search box. Click on Level Initializer. There are 3 offsets: X, Y Z . Change Z Increase for higher, decrease for lower.","title":"Run XR Simulation"},{"location":"run_simulation/#run-simulation","text":"This document provides guidance for downloading, setting up, and running the simulation.","title":"Run Simulation"},{"location":"run_simulation/#download-the-project","text":"The project can be downloaded from this Google Drive folder . Due to the enormous size of the project, it cannot be hosted on Github. You can use 7Zip to unzip the project.","title":"Download the Project"},{"location":"run_simulation/#run-the-vr-simulation","text":"","title":"Run the VR simulation"},{"location":"run_simulation/#set-up-the-oculus-headset-before-setting-up-unreal-engine","text":"1. Turn on Oculus desktop program. 2. Turn on the headset. 3. Allow device to access data from the computer using the controller. 4. If Guardian is not found, create guardian using the controller. 5. Enable Oculus Link.","title":"Set up the Oculus Headset (before setting up Unreal Engine)"},{"location":"run_simulation/#set-up-the-unreal-engine","text":"1. Navigate to Carla_XR\\Unreal\\CarlaUE4, double click CarlaUE4.uproject to launch the Unreal project. 2. The Oculus link must be enabled before starting the Unreal Engine. 3. The Oculus app must show active connection before starting the Unreal Engine. 4. Navigate to \u201cContent\u201d \u2013 \u201cCarla\u201d \u2013 \u201cMaps\u201d and select the map(in bottom left of Unreal Engine) after launching the project. 5. There are 3 scenarios being adjusted for this project, which are Rural(Town07), City(Town10HD), and Highway(Town05).","title":"Set up the Unreal Engine"},{"location":"run_simulation/#set-up-the-flask-server","text":"1. Open a new command window and navigate to directory G29/test . 2. Run the server: python angle_sim.py 3. The server must be running before executing any simulation.","title":"Set up the Flask Server"},{"location":"run_simulation/#set-up-the-g29-wheel","text":"1. Open a new command window and navigate to directory G29/test . 2. Run the server : nodepython angle_phy.jspy 3. The wheel script must be running before executing any simulation","title":"Set up the G29 Wheel"},{"location":"run_simulation/#set-up-the-scenario-demo-for-vr","text":"1. Navigate to Carla\\PythonAPI\\scenes 2. Click play on the Unreal scene 3. Select VR Mode using spacebar 4. Run the script 5. Always close the Python script before exiting Unreal scene","title":"Set up the Scenario Demo for VR"},{"location":"run_simulation/#run-the-mr-simulation","text":"Most procedures for running the MR simulation is the same as VR. Instead of using Oculus Link, you should compile the Unity project under Unity\\CARLAUnityMR folder as Apk , and install it on Quest2.","title":"Run the MR simulation"},{"location":"run_simulation/#set-up-the-scenario-demo-for-mr","text":"1. Navigate to Carla\\PythonAPI\\scenes 2. Click play on the Unreal scene 3. Open the compiled CARLAUnityMR App on Quest2 4. Open NDI to Spout.exe under SPOUTtoNDI\\bin 3. Select MR Mode using spacebar 4. Run the script 5. Always close the Python script before exiting Unreal scene Although MR is implemented, the result is undesireable.","title":"Set up the Scenario Demo for MR"},{"location":"run_simulation/#calibration","text":"In Unreal project, type init in the top right search box. Click on Level Initializer. There are 3 offsets: X, Y Z . Change Z Increase for higher, decrease for lower.","title":"Calibration"},{"location":"vel_mesh_render_n_collision/","text":"Vehicle Mesh Rendering and Collision CARLA is designed primarily for autonomous driving research and used in third-person perspective, bird`s-eye view, or even without rendering. Therefore, the vehicle meshes and textures that come with CARLA have a low Level of Detail (LOD). To extend it as a VR application, a high LOD vehicle model should be imported and adjusted to be suitable in the CARLA environment. After searching and comparison on a variety of models from Unreal Marketplace and TurboSquid, an Audi A6 model from the Car Configurator project, which is licensed for free to use when working with Unreal Engine, developed by Epic Games and Audi was chosen. The model was extracted from the Car Configurator project after cleaning irrelevant Blueprint nodes inside the Car Configurator project. Unlike the Car Configurator project, it is unnecessary and unable for users of a VR autonomous driving simulator to see some components for functionalities, such as the engine and machine for the retractable top. Keeping them would consume much computational power as more polygons need to be rendered at every frame, which is amplified when using stereo rendering per frame in VR. Therefore, imperceptible components in VR were removed before importing the model to CARLA. CARLA stores vehicles as Blueprint classes. Each vehicle Blueprint contains a set of sensors for autonomous driving, and each four-wheeled vehicle was rigged with the same base skeleton. To avoid potential conflicts between mesh and skeleton when rigging and incompatibilities between mesh and sensor Blueprint, the vehicle mesh rendering and collision were handled separately. Because Audi A6, the model extracted from the Car Configurator, and Tesla Model 3, a vehicle Blueprint class already inside the CARLA project, has roughly the same dimension and hitbox both visually and physically, the Tesla Model 3 Blueprint was chosen to be responsible for handling collision. The initialization procedures were also programmed in the AutoAttachedCamera Blueprint. When a player-controlled Tesla Model 3 is spawned, besides repositioning the VR camera, the AutoAttachedCamera Blueprint also disables the mesh rendering of the low LOD Tesla Model 3, spawns the high LOD Audi A6, and disables its collider. This method can not only avoid the potential conflicts among mesh, skeleton, and Blueprint sensors but also can optimize the performance by showing the high-fidelity model and calculating the collisions using considerably fewer polygons.","title":"Vehicle Mesh Rendering and Collision"},{"location":"vel_mesh_render_n_collision/#vehicle-mesh-rendering-and-collision","text":"CARLA is designed primarily for autonomous driving research and used in third-person perspective, bird`s-eye view, or even without rendering. Therefore, the vehicle meshes and textures that come with CARLA have a low Level of Detail (LOD). To extend it as a VR application, a high LOD vehicle model should be imported and adjusted to be suitable in the CARLA environment. After searching and comparison on a variety of models from Unreal Marketplace and TurboSquid, an Audi A6 model from the Car Configurator project, which is licensed for free to use when working with Unreal Engine, developed by Epic Games and Audi was chosen. The model was extracted from the Car Configurator project after cleaning irrelevant Blueprint nodes inside the Car Configurator project. Unlike the Car Configurator project, it is unnecessary and unable for users of a VR autonomous driving simulator to see some components for functionalities, such as the engine and machine for the retractable top. Keeping them would consume much computational power as more polygons need to be rendered at every frame, which is amplified when using stereo rendering per frame in VR. Therefore, imperceptible components in VR were removed before importing the model to CARLA. CARLA stores vehicles as Blueprint classes. Each vehicle Blueprint contains a set of sensors for autonomous driving, and each four-wheeled vehicle was rigged with the same base skeleton. To avoid potential conflicts between mesh and skeleton when rigging and incompatibilities between mesh and sensor Blueprint, the vehicle mesh rendering and collision were handled separately. Because Audi A6, the model extracted from the Car Configurator, and Tesla Model 3, a vehicle Blueprint class already inside the CARLA project, has roughly the same dimension and hitbox both visually and physically, the Tesla Model 3 Blueprint was chosen to be responsible for handling collision. The initialization procedures were also programmed in the AutoAttachedCamera Blueprint. When a player-controlled Tesla Model 3 is spawned, besides repositioning the VR camera, the AutoAttachedCamera Blueprint also disables the mesh rendering of the low LOD Tesla Model 3, spawns the high LOD Audi A6, and disables its collider. This method can not only avoid the potential conflicts among mesh, skeleton, and Blueprint sensors but also can optimize the performance by showing the high-fidelity model and calculating the collisions using considerably fewer polygons.","title":"Vehicle Mesh Rendering and Collision"},{"location":"vr_cam_attachment/","text":"VR Camera Attachment The CARLA project was originally designed to use Unreal Engine purely for the environment and handle events and video output using Pygame. It is hard to implement VR directly on the client-side as Pygame barely has VR support. Therefore, VR was implemented on the server. To solve the discrepancy between client spawning event and server VR video output, a Blueprint class, which is a unique data structure when programming using Blueprint, the visualized programming interface inside Unreal Engine, named AutoAttachedCamera was developed, which is responsible for checking if the player vehicle exists and attach it to the spawned player vehicle automatically. it checks if a player-controlled vehicle exists and if it already attached itself to a vehicle at every frame. If a player-controller vehicle exists and it is not attached yet, it will transform itself into the driver seat of the vehicle. It also works after destroying the previous player vehicle and initializing a new one multiple times. In this way, the spawning event was properly handled between client and server.","title":"VR Camera Attachment"},{"location":"vr_cam_attachment/#vr-camera-attachment","text":"The CARLA project was originally designed to use Unreal Engine purely for the environment and handle events and video output using Pygame. It is hard to implement VR directly on the client-side as Pygame barely has VR support. Therefore, VR was implemented on the server. To solve the discrepancy between client spawning event and server VR video output, a Blueprint class, which is a unique data structure when programming using Blueprint, the visualized programming interface inside Unreal Engine, named AutoAttachedCamera was developed, which is responsible for checking if the player vehicle exists and attach it to the spawned player vehicle automatically. it checks if a player-controlled vehicle exists and if it already attached itself to a vehicle at every frame. If a player-controller vehicle exists and it is not attached yet, it will transform itself into the driver seat of the vehicle. It also works after destroying the previous player vehicle and initializing a new one multiple times. In this way, the spawning event was properly handled between client and server.","title":"VR Camera Attachment"}]}